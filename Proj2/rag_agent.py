from typing import List, Dict, Optional, Tuple, Any
import json
from openai import OpenAI

from config import (
    OPENAI_API_KEY,
    OPENAI_API_BASE,
    MODEL_NAME,
    TOP_K,
)
from vector_store import VectorStore


class RAGAgent:
    def __init__(
        self,
        model: str = MODEL_NAME,
    ):
        self.model = model

        self.client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_API_BASE)

        self.vector_store = VectorStore()

        """
        TODO: å®ç°å¹¶è°ƒæ•´ç³»ç»Ÿæç¤ºè¯ï¼Œä½¿å…¶ç¬¦åˆè¯¾ç¨‹åŠ©æ•™çš„è§’è‰²å’Œå›ç­”ç­–ç•¥
        """
        self.rag_system_prompt = (
            "ä½ æ˜¯ä¸€ä½å‹å¥½ã€ä¸“ä¸šä¸”ç»†å¿ƒçš„è¯¾ç¨‹åŠ©æ•™ã€‚\n"
            "ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„ã€è¯¾ç¨‹å†…å®¹ã€‘å›ç­”å­¦ç”Ÿé—®é¢˜ã€‚\n"
            "**è§„åˆ™:**\n"
            "1. ä»”ç»†é˜…è¯»ä¸Šä¸‹æ–‡ï¼Œç”¨æ¸…æ™°çš„ä¸­æ–‡å›ç­”ã€‚\n"
            "2. å¦‚æœé—®é¢˜ä¸è¯¾ç¨‹æ— å…³ä¸”ä¸å±äºé—²èŠï¼Œè¯·ç¤¼è²Œæ‹’ç»ã€‚\n"
            "3. å¿…é¡»åœ¨å›ç­”æœ«å°¾æ ‡æ³¨æ¥æºï¼Œæ ¼å¼ï¼š`[æ–‡ä»¶å - é¡µç ]`ã€‚\n"
        )
        self.general_system_prompt = (
            "ä½ æ˜¯ä¸€ä½åšå­¦ã€å‹å¥½çš„æ™ºèƒ½åŠ©æ‰‹ï¼ŒåŒæ—¶ä¹Ÿæ˜¯è¿™é—¨è¯¾çš„åŠ©æ•™ã€‚\n"
            "å¯¹äºç”¨æˆ·å‘èµ·çš„é—²èŠæˆ–ä¸è¯¾ç¨‹æ— å…³çš„é€šç”¨é—®é¢˜ï¼Œè¯·åˆ©ç”¨ä½ çš„é€šç”¨çŸ¥è¯†è¿›è¡Œæµç•…ã€è‡ªç„¶çš„å›ç­”ã€‚\n"
            "ä¸éœ€è¦å±€é™äºè¯¾ç¨‹å†…å®¹ï¼Œä¹Ÿä¸éœ€è¦å¼•ç”¨æ¥æºã€‚"
        )
        self.quiz_system_prompt = (
            "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„åŠ©æ•™ï¼Œä¹Ÿæ˜¯è€ƒè¯•å‡ºé¢˜äººã€‚\n"
            "ç”¨æˆ·çš„è¯·æ±‚å¯èƒ½åŒ…å«'è®²è§£'å’Œ'å‡ºé¢˜'ä¸¤ä¸ªéƒ¨åˆ†ï¼Œæˆ–è€…åªæ˜¯'å‡ºé¢˜'ã€‚\n"
            "**ä»»åŠ¡:**\n"
            "1. åŸºäºã€è¯¾ç¨‹å†…å®¹ã€‘ï¼Œæ ¹æ®ç”¨æˆ·æŒ‡ä»¤ç”Ÿæˆå›ç­”ã€‚\n"
            "2. å¦‚æœç”¨æˆ·è¦æ±‚å‡ºé¢˜ï¼Œè¯·ç¼–å†™ä¸€é“é«˜è´¨é‡çš„é¢˜ç›®ï¼ˆé€‰æ‹©æˆ–ç®€ç­”ï¼‰ï¼Œå¦‚æœç”¨æˆ·è¦æ±‚ï¼Œè¯·é™„å¸¦æ ‡å‡†ç­”æ¡ˆå’Œè§£æï¼ˆè§£æå¯ä»¥æŠ˜å æˆ–æ”¾åœ¨æœ€åï¼‰ã€‚å¦‚æœç”¨æˆ·è¦æ±‚ä¸æä¾›ç­”æ¡ˆï¼Œè¯·å…ˆä¸è¦æŠŠç­”æ¡ˆè¾“å‡ºã€‚\n"
            "3. é¢˜ç›®å¿…é¡»åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ï¼Œä¸è¦å‡­ç©ºç¼–é€ ã€‚ä½†ä¸å¿…é¡»æ˜¯èµ„æ–™åº“ä¸­å­˜åœ¨çš„åŸé¢˜ã€‚\n"
            "4. å¼•ç”¨æ¥æº(å¦‚æœé¢˜ç›®æ¥æºäºçŸ¥è¯†åº“ä¸­)ã€‚"
        )
        
    def _get_all_courses(self) -> List[str]:
        """
        è·å–æ‰€æœ‰è¯¾ç¨‹åç§°çš„åˆ—è¡¨
        """
        # ä»å‘é‡åº“ä¸­è·å–æ‰€æœ‰summaryï¼Œæå–è¯¾ç¨‹åç§°
        all_summaries = self.vector_store.get_overall_description()
        
        # æ”¹è¿›çš„promptï¼Œæ˜ç¡®è¦æ±‚JSONæ ¼å¼
        prompt = f"""
    è¯·ä»ä»¥ä¸‹è¯¾ç¨‹æ‘˜è¦ä¸­æå–æ‰€æœ‰è¯¾ç¨‹åç§°/ä¸‰çº§å­¦ç§‘åç§°ã€‚

    **è¦æ±‚ï¼š**
    1. åªæå–è¯¾ç¨‹åç§°ï¼Œä¸è¦å…¶ä»–å†…å®¹
    2. è¿”å›ä¸¥æ ¼çš„JSONæ•°ç»„æ ¼å¼
    3. æ ¼å¼ç¤ºä¾‹ï¼š["è¯¾ç¨‹1", "è¯¾ç¨‹2", "è¯¾ç¨‹3"]
    4. ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—

    è¯¾ç¨‹æ‘˜è¦ï¼š
    {all_summaries}

    è¯·è¿”å›JSONæ•°ç»„ï¼š
    """
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªJSONç”Ÿæˆå™¨ï¼Œåªè¿”å›æœ‰æ•ˆçš„JSONæ•°ç»„ï¼Œä¸è¦ä»»ä½•é¢å¤–æ–‡å­—ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,  # æ›´ä½çš„æ¸©åº¦ä¿è¯æ ¼å¼
            max_tokens=500
        )

        content = response.choices[0].message.content.strip()

        course_names = json.loads(content)
        return course_names

    def _clean_text(self, text: str) -> str:
        """
        æ¸…æ´—å­—ç¬¦ä¸²ï¼Œç§»é™¤æ— æ³•ç¼–ç çš„ä»£ç†å­—ç¬¦ï¼ˆSurrogatesï¼‰ï¼Œé˜²æ­¢ API è°ƒç”¨å´©æºƒ
        """
        if not text:
            return ""
        try:
            # å°è¯•ç¼–ç å†è§£ç ï¼Œå¿½ç•¥é”™è¯¯å­—ç¬¦
            return text.encode('utf-8', 'ignore').decode('utf-8')
        except Exception:
            # å¦‚æœå½»åº•å¤±è´¥ï¼Œè¿”å›ç©ºæˆ–åŸå§‹å€¼
            return ""
    def _analyze_intent(self, query: str) -> Dict:
        """
        ä½¿ç”¨ LLM åˆ†æç”¨æˆ·æ„å›¾ï¼Œè¿›è¡Œè·¯ç”±ã€‚
        è¿”å› JSON: {type, topic}
        """
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªæ„å›¾åˆ†ç±»å™¨ã€‚åˆ†æç”¨æˆ·è¾“å…¥ï¼š"{query}"
        
        è¿”å›ä¸¥æ ¼çš„ JSON æ ¼å¼ï¼ˆæ— Markdownï¼‰ï¼ŒåŒ…å«å­—æ®µï¼š
        1. type: (str) 
            - "greeting": æ‰“æ‹›å‘¼/é—²èŠ (å¦‚"ä½ å¥½", "åœ¨å—")
            - "irrelevant": ä¸è¯¾ç¨‹/ç ”ç©¶/å­¦ä¹ å®Œå…¨æ— å…³ (å¦‚"ä»Šå¤©å¤©æ°”", "è®²ä¸ªç¬‘è¯")
            - "quiz": è¦æ±‚å‡ºé¢˜/æµ‹éªŒ/è€ƒè¯•/è€ƒè€ƒæˆ‘ (åŒ…å«"è®²è§£å¹¶å‡ºé¢˜"çš„æ··åˆæ„å›¾ï¼Œåªè¦æœ‰å‡ºé¢˜éœ€æ±‚å°±ç®—)
            - "qa": æ™®é€šè¯¾ç¨‹æé—® (é»˜è®¤)
        2. topic: (str) æå–æ ¸å¿ƒçŸ¥è¯†ç‚¹å…³é”®è¯ï¼Œå¦‚æœæ˜¯é—²èŠåˆ™ä¸ºç©ºã€‚ä¸éœ€è¦å¤ªç²¾ç®€ï¼Œå¯ä»¥å°½é‡ä¿æŒåŸå§‹å†…å®¹ã€‚
        
        ç¤ºä¾‹ï¼š"ä½ å¥½" -> {{"type": "greeting", "topic": ""}}
        ç¤ºä¾‹ï¼š"å‡ºä¸ªAttentionçš„é¢˜" -> {{"type": "quiz", "topic": "Attention"}}
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1, # ä½æ¸©ä¿è¯æ ¼å¼
                max_tokens=100
            )
            content = response.choices[0].message.content.strip()
            # æ¸…æ´—å¯èƒ½å­˜åœ¨çš„ Markdown æ ‡è®°
            if content.startswith("```"):
                content = content.replace("```json", "").replace("```", "")
            return json.loads(content)
        except:
            # é™çº§ï¼šé»˜è®¤ QA
            return {"type": "qa", "topic": query}
    def _format_context(self, docs: List[Dict]) -> str:
        context_parts = []
        for i, doc in enumerate(docs):
            content = doc.get("content", "")
            metadata = doc.get("metadata", {})
            file_name = metadata.get("filename", "æœªçŸ¥æ–‡ä»¶")
            page = metadata.get("page_number", 0)
            page_label = f"é¡µç {page}" if page else "æ— é¡µç "
            
            source_info = f"[æ¥æº: {file_name} - {page_label}]"
            context_parts.append(f"--- ç‰‡æ®µ {i+1} ---\n{content}\n{source_info}\n")
        return "\n".join(context_parts)

    def retrieve_context(
        self, query: str, top_k: int = TOP_K
    ) -> Tuple[str, List[Dict]]:
        """
        æ ‡å‡†æ£€ç´¢æ–¹æ³• (ç”¨äºæ™®é€šé—®ç­”)
        """
        # 1. ä½¿ç”¨æ ‡å‡†æ£€ç´¢
        retrieved_docs = self.vector_store.search(query=query, top_k=top_k)
        
        # 2. è°ƒç”¨é€šç”¨æ ¼å¼åŒ–å‡½æ•°
        context = self._format_context(retrieved_docs)
        
        return context, retrieved_docs

    def generate_response(
        self,
        query: str,
        context: Optional[str] = None,
        chat_history: Optional[List[Dict]] = None,
        system_prompt: str = ""
    ) -> str:
        """
        ç”Ÿæˆå›ç­”ï¼šæ ¹æ®æ˜¯å¦æœ‰ Context åŠ¨æ€æ„å»º User Prompt
        """
        clean_sys_prompt = self._clean_text(system_prompt)
        messages = [{"role": "system", "content": system_prompt}]
        if chat_history:
            for msg in chat_history:
                clean_msg = {
                    "role": msg["role"],
                    "content": self._clean_text(msg["content"])
                }
                messages.append(clean_msg)

        # === åŠ¨æ€æ„å»º User Prompt ===
        if context:
            # åœºæ™¯ A: æœ‰ RAG ä¸Šä¸‹æ–‡ (QA / Quiz)
            clean_context = self._clean_text(context)
            clean_query = self._clean_text(query)
            
            user_text = f"""
è¯·åŸºäºä¸‹é¢æä¾›çš„ã€è¯¾ç¨‹å†…å®¹ã€‘æ¥å›ç­”ç”¨æˆ·æŒ‡ä»¤ã€‚

---
ã€ç”¨æˆ·æŒ‡ä»¤ã€‘
{clean_query}

---
ã€è¯¾ç¨‹å†…å®¹ã€‘
{clean_context}

---
è¯·ä¸¥æ ¼æŒ‰ç…§ç³»ç»Ÿæç¤ºè¯çš„è¦æ±‚æ¥ç»„ç»‡ä½ çš„å›ç­”ã€‚
"""
        else:
            # åœºæ™¯ B: æ— ä¸Šä¸‹æ–‡ (Greeting / Irrelevant)
            # ç›´æ¥æŠŠç”¨æˆ·é—®é¢˜å‘ç»™å¤§æ¨¡å‹ï¼Œä¸åŠ ä»»ä½• RAG é™åˆ¶
            user_text = query

        messages.append({"role": "user", "content": user_text})

        try:

            print(f"æŠ•å–‚å†…å®¹ï¼š{messages}")
            response = self.client.chat.completions.create(
                model=self.model, messages=messages, temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"ç”Ÿæˆå›ç­”å‡ºé”™: {str(e)}"

    def answer_question(
        self, query: str, chat_history: Optional[List[Dict]] = None, top_k: int = TOP_K
    ) -> str:
        actual_query_to_llm = query 
        # 1. æ„å›¾è·¯ç”±
        print(" Â Thinking: åˆ†ææ„å›¾...")
        intent = self._analyze_intent(query)
        intent_type = intent.get("type", "qa")
        topic = intent.get("topic", query)
        print(f" Â Intent: [{intent_type}] Topic: [{topic}]")

        retrieved_docs = []
        final_context = None
        current_system_prompt = self.general_system_prompt # é»˜è®¤ä¸ºé€šç”¨

        # === è·¯ç”±åˆ†æ”¯ ===

        # åˆ†æ”¯ A: çº¯é€šç”¨æ¨¡å¼ (Greeting / Irrelevant) -> ä¸æ£€ç´¢
        if intent_type in ["greeting", "irrelevant"]:
            # ä¸æ£€ç´¢ï¼Œfinal_context ä¿æŒä¸º None
            # System Prompt ä½¿ç”¨ general_system_prompt
            pass 

        # åˆ†æ”¯ B: å‡ºé¢˜æ¨¡å¼ -> æ··åˆæ£€ç´¢
        elif intent_type == "quiz":
            current_system_prompt = self.quiz_system_prompt
            retrieved_docs = self.vector_store.search_hybrid(query=topic, top_k=top_k, pool_size=20)
            final_context = self._format_context(retrieved_docs)
            if not final_context: final_context = "ï¼ˆæœªæ‰¾åˆ°ç›¸å…³èµ„æ–™ï¼Œè¯·å°è¯•æ ¹æ®é€šç”¨çŸ¥è¯†å‡ºé¢˜ï¼‰"

        # åˆ†æ”¯ C: è¯¾ç¨‹é—®ç­” -> æ ‡å‡†æ£€ç´¢
        else: # qa
            print(f" Â Retrieving: æœç´¢ [{topic}]...")
            retrieved_docs = self.vector_store.search(query=topic, top_k=top_k)
            
            # === [æ–°å¢] é˜ˆå€¼åˆ¤æ–­é€»è¾‘ ===
            # å‡è®¾é˜ˆå€¼è®¾ä¸º 1.0 (ä½ å¯ä»¥æ ¹æ® log è°ƒæ•´)
            SIMILARITY_THRESHOLD = 1.0 
            
            is_relevant = False
            
            if retrieved_docs:
                # è·å–ç¬¬ä¸€æ¡ç»“æœçš„è·ç¦»
                first_dist = retrieved_docs[0].get("distance", 999)
                print(f" Â > Top-1 Distance: {first_dist:.4f}") # æ‰“å°å‡ºæ¥æ–¹ä¾¿è°ƒè¯•
                
                if first_dist < SIMILARITY_THRESHOLD:
                    is_relevant = True
                else:
                    print(f" Â ! è·ç¦»è¿‡å¤§ (>{SIMILARITY_THRESHOLD})ï¼Œåˆ¤å®šä¸ºæ— å…³å†…å®¹")
            
            # === åˆ†æ”¯åˆ¤æ–­ ===
            
            if is_relevant:
                # Case C1: æ‰¾åˆ°äº† *é«˜è´¨é‡* èµ„æ–™ -> æ­£å¸¸ RAG
                current_system_prompt = self.rag_system_prompt
                final_context = self._format_context(retrieved_docs)
            else:
                # Case C2: æ²¡æ‰¾åˆ° æˆ– ç»“æœå¤ªå·® -> ä¼˜é›…é™çº§
                print(" Â ! æ£€ç´¢ç»“æœä¸ºç©ºæˆ–ä¸ç›¸å…³ï¼Œåˆ‡æ¢è‡³é€šç”¨å›ç­”æ¨¡å¼")
                
                current_system_prompt = self.general_system_prompt
                final_context = None
                
                # æ³¨å…¥é€šç”¨å›ç­”æŒ‡ä»¤
                actual_query_to_llm = (
                    f"{query}\n\n"
                    "---------------------\n"
                    "ã€ç³»ç»ŸæŒ‡ä»¤ã€‘\n"
                    "çŸ¥è¯†åº“æ£€ç´¢ç»“æœä¸ºç©ºï¼ˆæˆ–ç›¸å…³åº¦è¿‡ä½ï¼‰ã€‚è¿™æ„å‘³ç€è¯¾ç¨‹èµ„æ–™ä¸­æ²¡æœ‰æåŠæ­¤å†…å®¹ã€‚\n"
                    "è¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š\n"
                    "1. é¦–å…ˆæ˜ç¡®å£°æ˜ï¼š'**æ ¹æ®å½“å‰çš„è¯¾ç¨‹èµ„æ–™ï¼Œæœªæ‰¾åˆ°ä¸è¯¥é—®é¢˜ç›¸å…³çš„å†…å®¹ã€‚**'\n"
                    "2. ç„¶åè¯´ï¼š'ä»¥ä¸‹æ˜¯æˆ‘åŸºäºé€šç”¨çŸ¥è¯†ä¸ºæ‚¨æä¾›çš„è§£ç­”ï¼š'\n"
                    "3. æœ€ååŸºäºä½ çš„é€šç”¨çŸ¥è¯†åº“å›ç­”è¯¥é—®é¢˜ã€‚"
                )

        # 2. ç”Ÿæˆå›ç­”
        # æ³¨æ„ï¼šè¿™é‡Œä¼ å…¥çš„æ˜¯ actual_query_to_llm
        answer = self.generate_response(
            query=actual_query_to_llm, 
            context=final_context, 
            chat_history=chat_history,
            system_prompt=current_system_prompt
        )

        return answer

    def chat(self) -> None:
        """äº¤äº’å¼å¯¹è¯"""
        
        ASSISTANT_NAME = "dinner" # åŠ©æ•™ç³»ç»Ÿåç§°

        dinner_ascii = r"""
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â•â•   â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘
    â•šâ•â•â•â•â•â•  â•šâ•â• â•šâ•â•  â•šâ•â•â•â•â•š â•â•  â•šâ•â•â•â• â•šâ•â•â•â•â•â•â• â•šâ•â•  â•šâ•â•
        """

        
        # 1. æ‰“å°åŠ©æ•™ç³»ç»Ÿåç§°å’Œæ¬¢è¿ä¿¡æ¯
        print("=" * 60)
        print(dinner_ascii)
        print(f"ğŸŒŸ æ¬¢è¿ä½¿ç”¨ã€{ASSISTANT_NAME}ã€‘æ™ºèƒ½è¯¾ç¨‹åŠ©æ•™ç³»ç»Ÿï¼")
        print("ï¼ˆå·²å¯ç”¨çŸ¥è¯†åº“æ£€ç´¢ã€æ„å›¾è·¯ç”±åŠä¹ é¢˜å‡ºé¢˜åŠŸèƒ½ï¼‰")
        print("-" * 60)
        
        # 2. è·å–å¹¶æ‰“å°è¯¾ç¨‹åˆ—è¡¨
        try:
            print("â³ æ­£åœ¨åŠ è½½çŸ¥è¯†åº“ä¸­çš„è¯¾ç¨‹åˆ—è¡¨...")
            # æ³¨æ„ï¼šself._get_all_courses() éœ€è¦è°ƒç”¨å¤–éƒ¨ APIï¼Œå¯èƒ½ä¼šè€—æ—¶
            course_names = self._get_all_courses()
            if course_names and isinstance(course_names, list):
                print("ğŸ“š å½“å‰çŸ¥è¯†åº“åŒ…å«çš„è¯¾ç¨‹ï¼š")
                for i, course in enumerate(course_names):
                    print(f" {i+1}. {course}")
            else:
                print("âš ï¸ æœªèƒ½åŠ è½½è¯¾ç¨‹åˆ—è¡¨æˆ–çŸ¥è¯†åº“ä¸ºç©ºã€‚")
        except Exception as e:
            print(f"âŒ åŠ è½½è¯¾ç¨‹åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            
        print("=" * 60)
        
        chat_history = []

        while True:
            
            # æ”¹è¿›è¾“å…¥æç¤º
            query = input(f"\nğŸ‘¤ å­¦ç”Ÿæé—® : ").strip()

            if not query:
                continue

            if query.lower() in ["exit", "quit", "bye", "é€€å‡º"]:
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨è¯¾ç¨‹åŠ©æ•™ç³»ç»Ÿï¼ŒæœŸå¾…ä¸‹æ¬¡è§é¢ï¼å†è§ï¼")
                break

            answer = self.answer_question(query, chat_history=chat_history)



            # æ”¹è¿›è¾“å‡ºæç¤º
            print(f"\nğŸ’¡ åŠ©æ•™: {answer}")

            # æ›´æ–°å¯¹è¯å†å² (ä»…å­˜å‚¨ç”¨æˆ·æŸ¥è¯¢å’ŒåŠ©æ•™å›ç­”ï¼Œç”¨äºç»´æŠ¤ä¸Šä¸‹æ–‡)
            chat_history.append({"role": "user", "content": query})
            chat_history.append({"role": "assistant", "content": answer})
